{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dataiku\n",
    "from dataiku import pandasutils as pdu\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <button style=\"display:none\" \n",
       "            class=\"btn btn-default ipython-export-btn\" \n",
       "            id=\"btn-df-4a7083a8-a617-4753-993c-5128cc4374fd\" \n",
       "            onclick=\"_export_df('4a7083a8-a617-4753-993c-5128cc4374fd')\">\n",
       "                Export dataframe\n",
       "            </button>\n",
       "            \n",
       "            <script>\n",
       "                \n",
       "                function _check_export_df_possible(dfid,yes_fn,no_fn) {\n",
       "                    console.log('Checking dataframe exportability...')\n",
       "                    if(!IPython || !IPython.notebook || !IPython.notebook.kernel || !IPython.notebook.kernel) {\n",
       "                        console.log('Export is not possible (IPython kernel is not available)')\n",
       "                        if(no_fn) {\n",
       "                            no_fn();\n",
       "                        }\n",
       "                    } else {\n",
       "                        var pythonCode = 'from dataiku.notebook.export import IPythonExporter;IPythonExporter._check_export_stdout(\"'+dfid+'\")';\n",
       "                        IPython.notebook.kernel.execute(pythonCode,{iopub: {output: function(resp) {\n",
       "                            console.info(\"Exportability response\", resp);\n",
       "                            var size = /^([0-9]+)x([0-9]+)$/.exec(resp.content.data || resp.content.text)\n",
       "                            if(!size) {\n",
       "                                console.log('Export is not possible (dataframe is not in-memory anymore)')\n",
       "                                if(no_fn) {\n",
       "                                    no_fn();\n",
       "                                }\n",
       "                            } else {\n",
       "                                console.log('Export is possible')\n",
       "                                if(yes_fn) {\n",
       "                                    yes_fn(1*size[1],1*size[2]);\n",
       "                                }\n",
       "                            }\n",
       "                        }}});\n",
       "                    }\n",
       "                }\n",
       "            \n",
       "                function _export_df(dfid) {\n",
       "                    \n",
       "                    var btn = $('#btn-df-'+dfid);\n",
       "                    var btns = $('.ipython-export-btn');\n",
       "                    \n",
       "                    _check_export_df_possible(dfid,function() {\n",
       "                        \n",
       "                        window.parent.openExportModalFromIPython('Pandas dataframe',function(data) {\n",
       "                            btns.prop('disabled',true);\n",
       "                            btn.text('Exporting...');\n",
       "                            var command = 'from dataiku.notebook.export import IPythonExporter;IPythonExporter._run_export(\"'+dfid+'\",\"'+data.exportId+'\")';\n",
       "                            var callback = {iopub:{output: function(resp) {\n",
       "                                _check_export_df_possible(dfid,function(rows, cols) {\n",
       "                                    $('#btn-df-'+dfid)\n",
       "                                        .css('display','inline-block')\n",
       "                                        .text('Export this dataframe ('+rows+' rows, '+cols+' cols)')\n",
       "                                        .prop('disabled',false);\n",
       "                                },function() {\n",
       "                                    $('#btn-df-'+dfid).css('display','none');\n",
       "                                });\n",
       "                            }}};\n",
       "                            IPython.notebook.kernel.execute(command,callback,{silent:false}); // yes, silent now defaults to true. figures.\n",
       "                        });\n",
       "                    \n",
       "                    }, function(){\n",
       "                            alert('Unable to export : the Dataframe object is not loaded in memory');\n",
       "                            btn.css('display','none');\n",
       "                    });\n",
       "                    \n",
       "                }\n",
       "                \n",
       "                (function(dfid) {\n",
       "                \n",
       "                    var retryCount = 10;\n",
       "                \n",
       "                    function is_valid_websock(s) {\n",
       "                        return s && s.readyState==1;\n",
       "                    }\n",
       "                \n",
       "                    function check_conn() {\n",
       "                        \n",
       "                        if(!IPython || !IPython.notebook) {\n",
       "                            // Don't even try to go further\n",
       "                            return;\n",
       "                        }\n",
       "                        \n",
       "                        // Check if IPython is ready\n",
       "                        console.info(\"Checking conn ...\")\n",
       "                        if(IPython.notebook.kernel\n",
       "                        && IPython.notebook.kernel\n",
       "                        && is_valid_websock(IPython.notebook.kernel.ws)\n",
       "                        ) {\n",
       "                            \n",
       "                            _check_export_df_possible(dfid,function(rows, cols) {\n",
       "                                $('#btn-df-'+dfid).css('display','inline-block');\n",
       "                                $('#btn-df-'+dfid).text('Export this dataframe ('+rows+' rows, '+cols+' cols)');\n",
       "                            });\n",
       "                            \n",
       "                        } else {\n",
       "                            console.info(\"Conditions are not ok\", IPython.notebook.kernel);\n",
       "                            \n",
       "                            // Retry later\n",
       "                            \n",
       "                            if(retryCount>0) {\n",
       "                                setTimeout(check_conn,500);\n",
       "                                retryCount--;\n",
       "                            }\n",
       "                            \n",
       "                        }\n",
       "                    };\n",
       "                    \n",
       "                    setTimeout(check_conn,100);\n",
       "                    \n",
       "                })(\"4a7083a8-a617-4753-993c-5128cc4374fd\");\n",
       "                \n",
       "            </script>\n",
       "            \n",
       "        <div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>invasive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  invasive\n",
       "0     1         0\n",
       "1     2         0\n",
       "2     3         1\n",
       "3     4         0\n",
       "4     5         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: load a DSS dataset as a Pandas dataframe\n",
    "mydataset = dataiku.Dataset(\"train_labels\")\n",
    "labels = mydataset.get_dataframe()\n",
    "labels.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Keras model in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# size of image\n",
    "smallimg_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2295\n"
     ]
    }
   ],
   "source": [
    "# get images list\n",
    "mypath = \"/data/pgutierrez/invasive/train\"\n",
    "images = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "random.shuffle(images)\n",
    "print len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2295/2295 [00:50<00:00, 45.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2295, 100, 100, 3)\n",
      "(2295,)\n",
      "(459, 100, 100, 3)\n",
      "(459,)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for f in tqdm(images, miniters=100):\n",
    "    im_number = int(f.split('.')[0])\n",
    "    y_train.append(int(labels[labels['name']==im_number]['invasive']))   \n",
    "    img = cv2.imread(mypath + \"/\"  + f.format(f))\n",
    "    x_train.append(cv2.resize(img, (smallimg_size, smallimg_size)))\n",
    "    \n",
    "y_train = np.array(y_train)\n",
    "x_train = np.array(x_train, np.float16) / 255.\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "split = 1836\n",
    "x_train, x_valid, y_train, y_valid = x_train[:split], x_train[split:], y_train[:split], y_train[split:]\n",
    "\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',\n",
    "                 input_shape=(smallimg_size,smallimg_size, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# save model weights for re init\n",
    "model.save_weights('innitial.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1836 samples, validate on 459 samples\n",
      "Epoch 1/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.6456 - acc: 0.6345 - val_loss: 0.5993 - val_acc: 0.6340\n",
      "Epoch 2/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.5547 - acc: 0.7211 - val_loss: 0.4428 - val_acc: 0.7908\n",
      "Epoch 3/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.4355 - acc: 0.7941 - val_loss: 0.4304 - val_acc: 0.7930\n",
      "Epoch 4/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.3720 - acc: 0.8393 - val_loss: 0.3350 - val_acc: 0.8410\n",
      "Epoch 5/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.3233 - acc: 0.8644 - val_loss: 0.3349 - val_acc: 0.8671\n",
      "Epoch 6/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.3680 - acc: 0.8393 - val_loss: 0.4704 - val_acc: 0.8279\n",
      "Epoch 7/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.3062 - acc: 0.8715 - val_loss: 0.2955 - val_acc: 0.8649\n",
      "Epoch 8/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.2343 - acc: 0.9025 - val_loss: 0.2636 - val_acc: 0.8932\n",
      "Epoch 9/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.1983 - acc: 0.9216 - val_loss: 0.2669 - val_acc: 0.8954\n",
      "Epoch 10/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.1876 - acc: 0.9270 - val_loss: 0.2921 - val_acc: 0.8584\n",
      "Epoch 11/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.1564 - acc: 0.9363 - val_loss: 0.3303 - val_acc: 0.8562\n",
      "Epoch 12/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.1231 - acc: 0.9499 - val_loss: 0.3326 - val_acc: 0.8932\n",
      "Epoch 13/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.0972 - acc: 0.9602 - val_loss: 0.3076 - val_acc: 0.8889\n",
      "Epoch 14/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.0864 - acc: 0.9630 - val_loss: 0.4787 - val_acc: 0.8214\n",
      "Epoch 15/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.1040 - acc: 0.9619 - val_loss: 0.2531 - val_acc: 0.9020\n",
      "Epoch 16/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.0715 - acc: 0.9733 - val_loss: 0.4080 - val_acc: 0.8671\n",
      "Epoch 17/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.0716 - acc: 0.9749 - val_loss: 0.3832 - val_acc: 0.8715\n",
      "Epoch 18/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.1153 - acc: 0.9575 - val_loss: 0.2661 - val_acc: 0.9063\n",
      "Epoch 19/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.0466 - acc: 0.9831 - val_loss: 0.3500 - val_acc: 0.9020\n",
      "Epoch 20/20\n",
      "1836/1836 [==============================] - 3s - loss: 0.0263 - acc: 0.9913 - val_loss: 0.3321 - val_acc: 0.8976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10115710>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('innitial.h5')\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416/459 [==========================>...] - ETA: 0sAUC:  0.966069688109\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.89      0.87       171\n",
      "          1       0.93      0.90      0.92       288\n",
      "\n",
      "avg / total       0.90      0.90      0.90       459\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yprobas = model.predict_proba(x_valid)\n",
    "ypred = [0 if x <0.5 else 1 for x in yprobas]\n",
    "print \"AUC: \", roc_auc_score(y_valid, yprobas, average='macro', sample_weight=None)\n",
    "print classification_report(y_valid,ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad for a first model ! However we missed the best one. Let's add some early stopping using keras callbacks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1836 samples, validate on 459 samples\n",
      "Epoch 1/10\n",
      "1836/1836 [==============================] - 3s - loss: 0.6439 - acc: 0.6324 - val_loss: 0.7090 - val_acc: 0.4009\n",
      "Epoch 2/10\n",
      "1836/1836 [==============================] - 3s - loss: 0.5695 - acc: 0.6944 - val_loss: 0.5101 - val_acc: 0.7712\n",
      "Epoch 3/10\n",
      "1836/1836 [==============================] - 3s - loss: 0.4740 - acc: 0.7734 - val_loss: 0.4956 - val_acc: 0.7691\n",
      "Epoch 4/10\n",
      "1836/1836 [==============================] - 3s - loss: 0.4162 - acc: 0.8170 - val_loss: 0.3945 - val_acc: 0.8322\n",
      "Epoch 5/10\n",
      "1836/1836 [==============================] - 3s - loss: 0.3592 - acc: 0.8426 - val_loss: 0.3298 - val_acc: 0.8562\n",
      "Epoch 6/10\n",
      "1836/1836 [==============================] - 3s - loss: 0.3111 - acc: 0.8791 - val_loss: 0.3640 - val_acc: 0.8388\n",
      "Epoch 7/10\n",
      "1836/1836 [==============================] - 3s - loss: 0.2547 - acc: 0.9020 - val_loss: 0.2637 - val_acc: 0.8932\n",
      "Epoch 8/10\n",
      "1836/1836 [==============================] - 3s - loss: 0.2418 - acc: 0.8992 - val_loss: 0.2599 - val_acc: 0.8954\n",
      "Epoch 9/10\n",
      "1836/1836 [==============================] - 3s - loss: 0.1959 - acc: 0.9205 - val_loss: 0.2436 - val_acc: 0.8976\n",
      "Epoch 10/10\n",
      "1836/1836 [==============================] - 3s - loss: 0.1350 - acc: 0.9423 - val_loss: 0.2363 - val_acc: 0.9041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xe396f10>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load innit model weights\n",
    "model.load_weights('innitial.h5')\n",
    "\n",
    "es = k.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_valid, y_valid),\n",
    "          callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416/459 [==========================>...] - ETA: 0sAUC:  0.967166179337\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.87      0.87       171\n",
      "          1       0.92      0.93      0.92       288\n",
      "\n",
      "avg / total       0.90      0.90      0.90       459\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yprobas = model.predict_proba(x_valid)\n",
    "ypred = [0 if x <0.5 else 1 for x in yprobas]\n",
    "print \"AUC: \", roc_auc_score(y_valid, yprobas, average='macro', sample_weight=None)\n",
    "print classification_report(y_valid,ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We may overfit quite fast because we have only a few lines. Let's try to augment the data ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wow ! awesome functionality ! \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.3,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.3,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=True)  # randomly flip images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "28/28 [==============================] - 3s - loss: 0.6733 - acc: 0.6189 - val_loss: 0.5989 - val_acc: 0.6275\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 2s - loss: 0.5870 - acc: 0.6454 - val_loss: 0.6308 - val_acc: 0.6492\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 2s - loss: 0.5691 - acc: 0.6980 - val_loss: 0.4960 - val_acc: 0.7625\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 2s - loss: 0.5813 - acc: 0.6885 - val_loss: 0.5306 - val_acc: 0.7451\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 2s - loss: 0.5963 - acc: 0.6858 - val_loss: 0.5230 - val_acc: 0.7255\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 2s - loss: 0.5610 - acc: 0.7023 - val_loss: 0.5042 - val_acc: 0.8039\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 2s - loss: 0.5324 - acc: 0.7248 - val_loss: 0.4405 - val_acc: 0.8322\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 2s - loss: 0.4729 - acc: 0.7707 - val_loss: 0.3790 - val_acc: 0.8083\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 2s - loss: 0.4349 - acc: 0.7786 - val_loss: 0.3406 - val_acc: 0.8562\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 2s - loss: 0.3874 - acc: 0.8259 - val_loss: 0.3148 - val_acc: 0.8606\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 2s - loss: 0.3260 - acc: 0.8491 - val_loss: 0.2735 - val_acc: 0.9020\n",
      "Epoch 12/30\n",
      "28/28 [==============================] - 2s - loss: 0.3753 - acc: 0.8306 - val_loss: 0.3757 - val_acc: 0.8170\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 2s - loss: 0.3466 - acc: 0.8481 - val_loss: 0.2580 - val_acc: 0.8976\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 2s - loss: 0.3096 - acc: 0.8617 - val_loss: 0.2328 - val_acc: 0.9041\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 2s - loss: 0.2801 - acc: 0.8841 - val_loss: 0.2516 - val_acc: 0.9107\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 2s - loss: 0.3078 - acc: 0.8636 - val_loss: 0.2176 - val_acc: 0.9216\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 2s - loss: 0.2899 - acc: 0.8764 - val_loss: 0.2148 - val_acc: 0.9194\n",
      "Epoch 18/30\n",
      "28/28 [==============================] - 2s - loss: 0.2594 - acc: 0.8885 - val_loss: 0.2632 - val_acc: 0.8889\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 2s - loss: 0.3131 - acc: 0.8669 - val_loss: 0.2206 - val_acc: 0.9259\n",
      "Epoch 20/30\n",
      "28/28 [==============================] - 2s - loss: 0.2716 - acc: 0.8861 - val_loss: 0.2027 - val_acc: 0.9259\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 2s - loss: 0.2487 - acc: 0.8982 - val_loss: 0.1985 - val_acc: 0.9194\n",
      "Epoch 22/30\n",
      "28/28 [==============================] - 2s - loss: 0.2613 - acc: 0.8933 - val_loss: 0.2128 - val_acc: 0.9237\n",
      "Epoch 23/30\n",
      "28/28 [==============================] - 2s - loss: 0.2603 - acc: 0.8926 - val_loss: 0.1876 - val_acc: 0.9303\n",
      "Epoch 24/30\n",
      "28/28 [==============================] - 2s - loss: 0.2716 - acc: 0.8866 - val_loss: 0.1914 - val_acc: 0.9325\n",
      "Epoch 25/30\n",
      "28/28 [==============================] - 2s - loss: 0.2461 - acc: 0.8946 - val_loss: 0.2035 - val_acc: 0.9259\n",
      "Epoch 26/30\n",
      "28/28 [==============================] - 2s - loss: 0.2628 - acc: 0.8927 - val_loss: 0.2184 - val_acc: 0.9150\n",
      "Epoch 27/30\n",
      "28/28 [==============================] - 2s - loss: 0.2661 - acc: 0.8896 - val_loss: 0.1917 - val_acc: 0.9237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xcf4a090>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load innit model weights\n",
    "model.load_weights('innitial.h5') \n",
    "\n",
    "# early stopping\n",
    "es = k.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=64),\n",
    "                    steps_per_epoch=len(x_train) / 64, epochs=30,validation_data=(x_valid, y_valid)\n",
    "                    ,callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416/459 [==========================>...] - ETA: 0sAUC:  0.977887426901\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.92      0.90       171\n",
      "          1       0.95      0.93      0.94       288\n",
      "\n",
      "avg / total       0.92      0.92      0.92       459\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yprobas = model.predict_proba(x_valid)\n",
    "ypred = [0 if x <0.5 else 1 for x in yprobas]\n",
    "print \"AUC: \", roc_auc_score(y_valid, yprobas, average='macro', sample_weight=None)\n",
    "print classification_report(y_valid,ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow ! Clear improovement ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to improove it with further data augmentation ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# wow ! awesome functionality ! \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "\n",
    "    \n",
    "    zoom_range = 0.5,\n",
    "    \n",
    "    rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.3,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.3,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=True)  # randomly flip images\n",
    "\n",
    "#datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "28/28 [==============================] - 3s - loss: 0.6524 - acc: 0.6261 - val_loss: 0.6649 - val_acc: 0.7102\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 2s - loss: 0.6115 - acc: 0.6410 - val_loss: 0.5725 - val_acc: 0.6993\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 2s - loss: 0.5966 - acc: 0.6536 - val_loss: 0.6126 - val_acc: 0.7756\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 2s - loss: 0.5746 - acc: 0.6877 - val_loss: 0.5197 - val_acc: 0.8061\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 2s - loss: 0.5119 - acc: 0.7379 - val_loss: 0.4501 - val_acc: 0.7734\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 2s - loss: 0.4956 - acc: 0.7366 - val_loss: 0.3858 - val_acc: 0.8497\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 2s - loss: 0.4201 - acc: 0.8121 - val_loss: 0.3378 - val_acc: 0.8627\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 2s - loss: 0.3870 - acc: 0.8170 - val_loss: 0.3330 - val_acc: 0.8693\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 2s - loss: 0.3775 - acc: 0.8314 - val_loss: 0.3416 - val_acc: 0.8584\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 2s - loss: 0.3885 - acc: 0.8305 - val_loss: 0.3588 - val_acc: 0.8388\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 2s - loss: 0.3634 - acc: 0.8320 - val_loss: 0.2700 - val_acc: 0.8867\n",
      "Epoch 12/30\n",
      "28/28 [==============================] - 2s - loss: 0.3377 - acc: 0.8554 - val_loss: 0.2657 - val_acc: 0.8824\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 2s - loss: 0.3455 - acc: 0.8495 - val_loss: 0.2243 - val_acc: 0.9041\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 2s - loss: 0.3121 - acc: 0.8674 - val_loss: 0.2329 - val_acc: 0.9085\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 2s - loss: 0.3282 - acc: 0.8588 - val_loss: 0.2402 - val_acc: 0.8932\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 2s - loss: 0.3223 - acc: 0.8503 - val_loss: 0.2330 - val_acc: 0.9063\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 2s - loss: 0.3059 - acc: 0.8690 - val_loss: 0.2082 - val_acc: 0.9129\n",
      "Epoch 18/30\n",
      "28/28 [==============================] - 2s - loss: 0.2852 - acc: 0.8731 - val_loss: 0.1942 - val_acc: 0.9259\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 2s - loss: 0.2956 - acc: 0.8832 - val_loss: 0.2038 - val_acc: 0.9259\n",
      "Epoch 20/30\n",
      "28/28 [==============================] - 2s - loss: 0.3150 - acc: 0.8620 - val_loss: 0.2419 - val_acc: 0.9107\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 2s - loss: 0.3021 - acc: 0.8748 - val_loss: 0.1889 - val_acc: 0.9368\n",
      "Epoch 22/30\n",
      "28/28 [==============================] - 2s - loss: 0.3011 - acc: 0.8778 - val_loss: 0.1969 - val_acc: 0.9259\n",
      "Epoch 23/30\n",
      "28/28 [==============================] - 2s - loss: 0.2753 - acc: 0.8847 - val_loss: 0.1880 - val_acc: 0.9325\n",
      "Epoch 24/30\n",
      "28/28 [==============================] - 2s - loss: 0.2835 - acc: 0.8863 - val_loss: 0.1870 - val_acc: 0.9325\n",
      "Epoch 25/30\n",
      "28/28 [==============================] - 2s - loss: 0.2638 - acc: 0.8921 - val_loss: 0.1828 - val_acc: 0.9390\n",
      "Epoch 26/30\n",
      "28/28 [==============================] - 2s - loss: 0.2725 - acc: 0.8905 - val_loss: 0.1830 - val_acc: 0.9390\n",
      "Epoch 27/30\n",
      "28/28 [==============================] - 2s - loss: 0.2734 - acc: 0.8864 - val_loss: 0.1826 - val_acc: 0.9434\n",
      "Epoch 28/30\n",
      "28/28 [==============================] - 2s - loss: 0.2816 - acc: 0.8897 - val_loss: 0.2019 - val_acc: 0.9346\n",
      "Epoch 29/30\n",
      "28/28 [==============================] - 2s - loss: 0.2815 - acc: 0.8860 - val_loss: 0.1915 - val_acc: 0.9325\n",
      "Epoch 30/30\n",
      "28/28 [==============================] - 2s - loss: 0.2901 - acc: 0.8811 - val_loss: 0.1788 - val_acc: 0.9325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xfb4c410>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load innit model weights\n",
    "model.load_weights('innitial.h5') \n",
    "\n",
    "# early stopping\n",
    "es = k.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=64),\n",
    "                    steps_per_epoch=len(x_train) / 64, epochs=30,validation_data=(x_valid, y_valid)\n",
    "                    ,callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416/459 [==========================>...] - ETA: 0sAUC:  0.976730019493\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.96      0.91       171\n",
      "          1       0.98      0.91      0.94       288\n",
      "\n",
      "avg / total       0.94      0.93      0.93       459\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yprobas = model.predict_proba(x_valid)\n",
    "ypred = [0 if x <0.5 else 1 for x in yprobas]\n",
    "print \"AUC: \", roc_auc_score(y_valid, yprobas, average='macro', sample_weight=None)\n",
    "print classification_report(y_valid,ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do our first submission ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1531 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1531/1531 [00:31<00:00, 49.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1531, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "# get images list\n",
    "mypath = \"/data/pgutierrez/invasive/test\"\n",
    "images = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "random.shuffle(images)\n",
    "print len(images)\n",
    "\n",
    "x_test = []\n",
    "names = []\n",
    "\n",
    "for f in tqdm(images, miniters=100):\n",
    "    im_number = int(f.split('.')[0])\n",
    "    names.append(im_number)\n",
    "    img = cv2.imread(mypath + \"/\"  + f.format(f))\n",
    "    x_test.append(cv2.resize(img, (smallimg_size, smallimg_size)))\n",
    "    \n",
    "x_test = np.array(x_test, np.float16) / 255.\n",
    "\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1531/1531 [==============================] - 1s     \n"
     ]
    }
   ],
   "source": [
    "# get the preds\n",
    "yprobas = model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <button style=\"display:none\" \n",
       "            class=\"btn btn-default ipython-export-btn\" \n",
       "            id=\"btn-df-acdfaf88-af3d-430c-aaf2-35cd52f9b0d9\" \n",
       "            onclick=\"_export_df('acdfaf88-af3d-430c-aaf2-35cd52f9b0d9')\">\n",
       "                Export dataframe\n",
       "            </button>\n",
       "            \n",
       "            <script>\n",
       "                \n",
       "                function _check_export_df_possible(dfid,yes_fn,no_fn) {\n",
       "                    console.log('Checking dataframe exportability...')\n",
       "                    if(!IPython || !IPython.notebook || !IPython.notebook.kernel || !IPython.notebook.kernel) {\n",
       "                        console.log('Export is not possible (IPython kernel is not available)')\n",
       "                        if(no_fn) {\n",
       "                            no_fn();\n",
       "                        }\n",
       "                    } else {\n",
       "                        var pythonCode = 'from dataiku.notebook.export import IPythonExporter;IPythonExporter._check_export_stdout(\"'+dfid+'\")';\n",
       "                        IPython.notebook.kernel.execute(pythonCode,{iopub: {output: function(resp) {\n",
       "                            console.info(\"Exportability response\", resp);\n",
       "                            var size = /^([0-9]+)x([0-9]+)$/.exec(resp.content.data || resp.content.text)\n",
       "                            if(!size) {\n",
       "                                console.log('Export is not possible (dataframe is not in-memory anymore)')\n",
       "                                if(no_fn) {\n",
       "                                    no_fn();\n",
       "                                }\n",
       "                            } else {\n",
       "                                console.log('Export is possible')\n",
       "                                if(yes_fn) {\n",
       "                                    yes_fn(1*size[1],1*size[2]);\n",
       "                                }\n",
       "                            }\n",
       "                        }}});\n",
       "                    }\n",
       "                }\n",
       "            \n",
       "                function _export_df(dfid) {\n",
       "                    \n",
       "                    var btn = $('#btn-df-'+dfid);\n",
       "                    var btns = $('.ipython-export-btn');\n",
       "                    \n",
       "                    _check_export_df_possible(dfid,function() {\n",
       "                        \n",
       "                        window.parent.openExportModalFromIPython('Pandas dataframe',function(data) {\n",
       "                            btns.prop('disabled',true);\n",
       "                            btn.text('Exporting...');\n",
       "                            var command = 'from dataiku.notebook.export import IPythonExporter;IPythonExporter._run_export(\"'+dfid+'\",\"'+data.exportId+'\")';\n",
       "                            var callback = {iopub:{output: function(resp) {\n",
       "                                _check_export_df_possible(dfid,function(rows, cols) {\n",
       "                                    $('#btn-df-'+dfid)\n",
       "                                        .css('display','inline-block')\n",
       "                                        .text('Export this dataframe ('+rows+' rows, '+cols+' cols)')\n",
       "                                        .prop('disabled',false);\n",
       "                                },function() {\n",
       "                                    $('#btn-df-'+dfid).css('display','none');\n",
       "                                });\n",
       "                            }}};\n",
       "                            IPython.notebook.kernel.execute(command,callback,{silent:false}); // yes, silent now defaults to true. figures.\n",
       "                        });\n",
       "                    \n",
       "                    }, function(){\n",
       "                            alert('Unable to export : the Dataframe object is not loaded in memory');\n",
       "                            btn.css('display','none');\n",
       "                    });\n",
       "                    \n",
       "                }\n",
       "                \n",
       "                (function(dfid) {\n",
       "                \n",
       "                    var retryCount = 10;\n",
       "                \n",
       "                    function is_valid_websock(s) {\n",
       "                        return s && s.readyState==1;\n",
       "                    }\n",
       "                \n",
       "                    function check_conn() {\n",
       "                        \n",
       "                        if(!IPython || !IPython.notebook) {\n",
       "                            // Don't even try to go further\n",
       "                            return;\n",
       "                        }\n",
       "                        \n",
       "                        // Check if IPython is ready\n",
       "                        console.info(\"Checking conn ...\")\n",
       "                        if(IPython.notebook.kernel\n",
       "                        && IPython.notebook.kernel\n",
       "                        && is_valid_websock(IPython.notebook.kernel.ws)\n",
       "                        ) {\n",
       "                            \n",
       "                            _check_export_df_possible(dfid,function(rows, cols) {\n",
       "                                $('#btn-df-'+dfid).css('display','inline-block');\n",
       "                                $('#btn-df-'+dfid).text('Export this dataframe ('+rows+' rows, '+cols+' cols)');\n",
       "                            });\n",
       "                            \n",
       "                        } else {\n",
       "                            console.info(\"Conditions are not ok\", IPython.notebook.kernel);\n",
       "                            \n",
       "                            // Retry later\n",
       "                            \n",
       "                            if(retryCount>0) {\n",
       "                                setTimeout(check_conn,500);\n",
       "                                retryCount--;\n",
       "                            }\n",
       "                            \n",
       "                        }\n",
       "                    };\n",
       "                    \n",
       "                    setTimeout(check_conn,100);\n",
       "                    \n",
       "                })(\"acdfaf88-af3d-430c-aaf2-35cd52f9b0d9\");\n",
       "                \n",
       "            </script>\n",
       "            \n",
       "        <div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>invasive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>926</td>\n",
       "      <td>0.999907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1160</td>\n",
       "      <td>0.063761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.119699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110</td>\n",
       "      <td>0.642412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1393</td>\n",
       "      <td>0.113904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>696</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>231</td>\n",
       "      <td>0.959795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>639</td>\n",
       "      <td>0.234656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1256</td>\n",
       "      <td>0.129205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>912</td>\n",
       "      <td>0.122278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>433</td>\n",
       "      <td>0.341717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1501</td>\n",
       "      <td>0.177891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>521</td>\n",
       "      <td>0.141616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>158</td>\n",
       "      <td>0.219738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>459</td>\n",
       "      <td>0.127018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1089</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>558</td>\n",
       "      <td>0.104929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>322</td>\n",
       "      <td>0.974468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>664</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>717</td>\n",
       "      <td>0.999971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>929</td>\n",
       "      <td>0.982756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>831</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>922</td>\n",
       "      <td>0.114734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>950</td>\n",
       "      <td>0.899074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>166</td>\n",
       "      <td>0.081723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>445</td>\n",
       "      <td>0.110577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>147</td>\n",
       "      <td>0.999972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>304</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>959</td>\n",
       "      <td>0.091146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1275</td>\n",
       "      <td>0.999993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>324</td>\n",
       "      <td>0.345043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>871</td>\n",
       "      <td>0.153662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1293</td>\n",
       "      <td>0.769006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>738</td>\n",
       "      <td>0.999892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1385</td>\n",
       "      <td>0.266130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>970</td>\n",
       "      <td>0.104456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>537</td>\n",
       "      <td>0.093025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>317</td>\n",
       "      <td>0.111638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>308</td>\n",
       "      <td>0.099519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>859</td>\n",
       "      <td>0.999800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>426</td>\n",
       "      <td>0.104456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>245</td>\n",
       "      <td>0.992719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>376</td>\n",
       "      <td>0.612046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>788</td>\n",
       "      <td>0.095005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>976</td>\n",
       "      <td>0.187744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>607</td>\n",
       "      <td>0.138016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>351</td>\n",
       "      <td>0.089406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1311</td>\n",
       "      <td>0.101662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>178</td>\n",
       "      <td>0.094874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>177</td>\n",
       "      <td>0.135716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>960</td>\n",
       "      <td>0.991795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>274</td>\n",
       "      <td>0.147176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1529</td>\n",
       "      <td>0.140487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1378</td>\n",
       "      <td>0.098050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>115</td>\n",
       "      <td>0.999344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1491</td>\n",
       "      <td>0.999968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1115</td>\n",
       "      <td>0.097555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1510</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>128</td>\n",
       "      <td>0.999959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1195</td>\n",
       "      <td>0.097081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>546</td>\n",
       "      <td>0.403540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>26</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>727</td>\n",
       "      <td>0.202614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>325</td>\n",
       "      <td>0.241650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>574</td>\n",
       "      <td>0.103145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1314</td>\n",
       "      <td>0.137711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1220</td>\n",
       "      <td>0.084851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>100</td>\n",
       "      <td>0.102216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>752</td>\n",
       "      <td>0.115091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>627</td>\n",
       "      <td>0.093776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>15</td>\n",
       "      <td>0.156369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1166</td>\n",
       "      <td>0.957616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>352</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>372</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>237</td>\n",
       "      <td>0.988055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>61</td>\n",
       "      <td>0.326153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1187</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>582</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>260</td>\n",
       "      <td>0.125606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1176</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>583</td>\n",
       "      <td>0.073805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>212</td>\n",
       "      <td>0.097312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>519</td>\n",
       "      <td>0.106768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1401</td>\n",
       "      <td>0.137600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1278</td>\n",
       "      <td>0.116930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1261</td>\n",
       "      <td>0.130565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>275</td>\n",
       "      <td>0.267141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>401</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>532</td>\n",
       "      <td>0.122591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>299</td>\n",
       "      <td>0.128983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>57</td>\n",
       "      <td>0.095315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>760</td>\n",
       "      <td>0.093411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1435</td>\n",
       "      <td>0.085830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>944</td>\n",
       "      <td>0.093231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1496</td>\n",
       "      <td>0.112733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>210</td>\n",
       "      <td>0.995745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1479</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1063</td>\n",
       "      <td>0.103624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>419</td>\n",
       "      <td>0.991474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>562</td>\n",
       "      <td>0.106127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>51</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>240</td>\n",
       "      <td>0.097242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1287</td>\n",
       "      <td>0.126036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>1106</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>1342</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.092953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>41</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>403</td>\n",
       "      <td>0.480396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>348</td>\n",
       "      <td>0.999985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>1094</td>\n",
       "      <td>0.523721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>1065</td>\n",
       "      <td>0.999775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>476</td>\n",
       "      <td>0.134379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>540</td>\n",
       "      <td>0.083440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>443</td>\n",
       "      <td>0.104335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>229</td>\n",
       "      <td>0.919646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>1403</td>\n",
       "      <td>0.129373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>971</td>\n",
       "      <td>0.102867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>1178</td>\n",
       "      <td>0.114432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>619</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>375</td>\n",
       "      <td>0.119854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>977</td>\n",
       "      <td>0.085743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>843</td>\n",
       "      <td>0.100796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>105</td>\n",
       "      <td>0.180744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>753</td>\n",
       "      <td>0.193526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>1247</td>\n",
       "      <td>0.131076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>1528</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>1239</td>\n",
       "      <td>0.088599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>1453</td>\n",
       "      <td>0.097373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>183</td>\n",
       "      <td>0.270575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>616</td>\n",
       "      <td>0.145413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>255</td>\n",
       "      <td>0.104056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>646</td>\n",
       "      <td>0.262905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>436</td>\n",
       "      <td>0.097064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>828</td>\n",
       "      <td>0.757767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1350</td>\n",
       "      <td>0.623605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>991</td>\n",
       "      <td>0.101421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>112</td>\n",
       "      <td>0.445139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>1053</td>\n",
       "      <td>0.091728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>1012</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>1168</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>456</td>\n",
       "      <td>0.102030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>805</td>\n",
       "      <td>0.999317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>180</td>\n",
       "      <td>0.473188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>1203</td>\n",
       "      <td>0.999223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>637</td>\n",
       "      <td>0.113355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>820</td>\n",
       "      <td>0.113329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>1080</td>\n",
       "      <td>0.162940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>882</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>1448</td>\n",
       "      <td>0.102992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>1427</td>\n",
       "      <td>0.189814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>821</td>\n",
       "      <td>0.183047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>852</td>\n",
       "      <td>0.087511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>1455</td>\n",
       "      <td>0.080328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>672</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>434</td>\n",
       "      <td>0.357060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>284</td>\n",
       "      <td>0.104086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>1292</td>\n",
       "      <td>0.152620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>1464</td>\n",
       "      <td>0.999034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>1369</td>\n",
       "      <td>0.094028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>1297</td>\n",
       "      <td>0.124803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>823</td>\n",
       "      <td>0.909706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>767</td>\n",
       "      <td>0.098573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>397</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>121</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>485</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>503</td>\n",
       "      <td>0.134207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>701</td>\n",
       "      <td>0.999820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>673</td>\n",
       "      <td>0.137958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>979</td>\n",
       "      <td>0.127135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>773</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>1530</td>\n",
       "      <td>0.814193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>903</td>\n",
       "      <td>0.104935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>679</td>\n",
       "      <td>0.988819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>396</td>\n",
       "      <td>0.081201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>697</td>\n",
       "      <td>0.147915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>81</td>\n",
       "      <td>0.257767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>587</td>\n",
       "      <td>0.158257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>1382</td>\n",
       "      <td>0.117109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>633</td>\n",
       "      <td>0.994505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>1020</td>\n",
       "      <td>0.487701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>198</td>\n",
       "      <td>0.090307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>292</td>\n",
       "      <td>0.105278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>336</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>54</td>\n",
       "      <td>0.120346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>735</td>\n",
       "      <td>0.343584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>1199</td>\n",
       "      <td>0.373312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>910</td>\n",
       "      <td>0.095916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>1471</td>\n",
       "      <td>0.999025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>686</td>\n",
       "      <td>0.110998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>687</td>\n",
       "      <td>0.098781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>25</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>874</td>\n",
       "      <td>0.818259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>252</td>\n",
       "      <td>0.322634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>1251</td>\n",
       "      <td>0.188375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>1145</td>\n",
       "      <td>0.107504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>549</td>\n",
       "      <td>0.295060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>186</td>\n",
       "      <td>0.111137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>868</td>\n",
       "      <td>0.103232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>406</td>\n",
       "      <td>0.442048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>204</td>\n",
       "      <td>0.996990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>784</td>\n",
       "      <td>0.868207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>208</td>\n",
       "      <td>0.098719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>718</td>\n",
       "      <td>0.147937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>1444</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>808</td>\n",
       "      <td>0.121989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>1257</td>\n",
       "      <td>0.106911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>124</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1531 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  invasive\n",
       "0      926  0.999907\n",
       "1     1160  0.063761\n",
       "2      500  0.119699\n",
       "3      110  0.642412\n",
       "4     1393  0.113904\n",
       "5      696  1.000000\n",
       "6      231  0.959795\n",
       "7      639  0.234656\n",
       "8     1256  0.129205\n",
       "9      912  0.122278\n",
       "10     433  0.341717\n",
       "11    1501  0.177891\n",
       "12     521  0.141616\n",
       "13     158  0.219738\n",
       "14     459  0.127018\n",
       "15    1089  1.000000\n",
       "16     558  0.104929\n",
       "17     322  0.974468\n",
       "18     664  0.999996\n",
       "19     717  0.999971\n",
       "20     929  0.982756\n",
       "21     831  1.000000\n",
       "22     922  0.114734\n",
       "23     950  0.899074\n",
       "24     166  0.081723\n",
       "25     445  0.110577\n",
       "26     147  0.999972\n",
       "27     304  1.000000\n",
       "28     959  0.091146\n",
       "29    1275  0.999993\n",
       "30     324  0.345043\n",
       "31     871  0.153662\n",
       "32    1293  0.769006\n",
       "33     738  0.999892\n",
       "34    1385  0.266130\n",
       "35     970  0.104456\n",
       "36     537  0.093025\n",
       "37     317  0.111638\n",
       "38     308  0.099519\n",
       "39     859  0.999800\n",
       "40     426  0.104456\n",
       "41     245  0.992719\n",
       "42     376  0.612046\n",
       "43     788  0.095005\n",
       "44     976  0.187744\n",
       "45     607  0.138016\n",
       "46     351  0.089406\n",
       "47    1311  0.101662\n",
       "48     178  0.094874\n",
       "49     177  0.135716\n",
       "50     960  0.991795\n",
       "51     274  0.147176\n",
       "52    1529  0.140487\n",
       "53    1378  0.098050\n",
       "54     115  0.999344\n",
       "55    1491  0.999968\n",
       "56    1115  0.097555\n",
       "57    1510  1.000000\n",
       "58     128  0.999959\n",
       "59    1195  0.097081\n",
       "60     546  0.403540\n",
       "61      26  1.000000\n",
       "62     727  0.202614\n",
       "63     221  1.000000\n",
       "64     325  0.241650\n",
       "65     574  0.103145\n",
       "66    1314  0.137711\n",
       "67    1220  0.084851\n",
       "68     100  0.102216\n",
       "69     752  0.115091\n",
       "70     627  0.093776\n",
       "71      15  0.156369\n",
       "72    1166  0.957616\n",
       "73     352  1.000000\n",
       "74     372  0.999998\n",
       "75     237  0.988055\n",
       "76      61  0.326153\n",
       "77    1187  1.000000\n",
       "78     582  1.000000\n",
       "79     260  0.125606\n",
       "80    1176  1.000000\n",
       "81     583  0.073805\n",
       "82     212  0.097312\n",
       "83     519  0.106768\n",
       "84    1401  0.137600\n",
       "85    1278  0.116930\n",
       "86    1261  0.130565\n",
       "87     275  0.267141\n",
       "88     401  1.000000\n",
       "89     532  0.122591\n",
       "90     299  0.128983\n",
       "91      57  0.095315\n",
       "92     760  0.093411\n",
       "93    1435  0.085830\n",
       "94     944  0.093231\n",
       "95    1496  0.112733\n",
       "96     210  0.995745\n",
       "97    1479  1.000000\n",
       "98    1063  0.103624\n",
       "99     419  0.991474\n",
       "100    562  0.106127\n",
       "101     51  1.000000\n",
       "102    240  0.097242\n",
       "103   1333  1.000000\n",
       "104   1287  0.126036\n",
       "...    ...       ...\n",
       "1426  1106  1.000000\n",
       "1427  1342  1.000000\n",
       "1428  1001  0.092953\n",
       "1429    41  1.000000\n",
       "1430   403  0.480396\n",
       "1431   348  0.999985\n",
       "1432  1094  0.523721\n",
       "1433  1065  0.999775\n",
       "1434   476  0.134379\n",
       "1435   540  0.083440\n",
       "1436   443  0.104335\n",
       "1437   229  0.919646\n",
       "1438  1403  0.129373\n",
       "1439   971  0.102867\n",
       "1440  1178  0.114432\n",
       "1441   619  1.000000\n",
       "1442   375  0.119854\n",
       "1443   977  0.085743\n",
       "1444   843  0.100796\n",
       "1445   105  0.180744\n",
       "1446   753  0.193526\n",
       "1447  1247  0.131076\n",
       "1448  1528  1.000000\n",
       "1449  1239  0.088599\n",
       "1450  1453  0.097373\n",
       "1451   183  0.270575\n",
       "1452   616  0.145413\n",
       "1453   255  0.104056\n",
       "1454   646  0.262905\n",
       "1455   436  0.097064\n",
       "1456   828  0.757767\n",
       "1457  1350  0.623605\n",
       "1458   991  0.101421\n",
       "1459   112  0.445139\n",
       "1460  1053  0.091728\n",
       "1461  1012  1.000000\n",
       "1462  1168  0.999995\n",
       "1463   456  0.102030\n",
       "1464   805  0.999317\n",
       "1465   180  0.473188\n",
       "1466  1203  0.999223\n",
       "1467   637  0.113355\n",
       "1468   820  0.113329\n",
       "1469  1080  0.162940\n",
       "1470   882  0.999999\n",
       "1471  1448  0.102992\n",
       "1472  1427  0.189814\n",
       "1473   821  0.183047\n",
       "1474   852  0.087511\n",
       "1475  1455  0.080328\n",
       "1476   672  1.000000\n",
       "1477   434  0.357060\n",
       "1478   284  0.104086\n",
       "1479  1292  0.152620\n",
       "1480  1464  0.999034\n",
       "1481  1369  0.094028\n",
       "1482  1297  0.124803\n",
       "1483   823  0.909706\n",
       "1484   767  0.098573\n",
       "1485   397  1.000000\n",
       "1486   121  1.000000\n",
       "1487   485  1.000000\n",
       "1488   503  0.134207\n",
       "1489   701  0.999820\n",
       "1490   673  0.137958\n",
       "1491   979  0.127135\n",
       "1492   773  1.000000\n",
       "1493  1530  0.814193\n",
       "1494   903  0.104935\n",
       "1495   679  0.988819\n",
       "1496   396  0.081201\n",
       "1497   697  0.147915\n",
       "1498    81  0.257767\n",
       "1499   587  0.158257\n",
       "1500  1382  0.117109\n",
       "1501   633  0.994505\n",
       "1502   333  1.000000\n",
       "1503  1020  0.487701\n",
       "1504   198  0.090307\n",
       "1505   292  0.105278\n",
       "1506   336  1.000000\n",
       "1507    54  0.120346\n",
       "1508   735  0.343584\n",
       "1509  1199  0.373312\n",
       "1510   910  0.095916\n",
       "1511  1471  0.999025\n",
       "1512   686  0.110998\n",
       "1513   687  0.098781\n",
       "1514    25  0.999998\n",
       "1515   874  0.818259\n",
       "1516   252  0.322634\n",
       "1517  1251  0.188375\n",
       "1518  1145  0.107504\n",
       "1519   549  0.295060\n",
       "1520   186  0.111137\n",
       "1521   868  0.103232\n",
       "1522   406  0.442048\n",
       "1523   204  0.996990\n",
       "1524   784  0.868207\n",
       "1525   208  0.098719\n",
       "1526   718  0.147937\n",
       "1527  1444  1.000000\n",
       "1528   808  0.121989\n",
       "1529  1257  0.106911\n",
       "1530   124  1.000000\n",
       "\n",
       "[1531 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame(np.stack([names,yprobas.reshape(1531,)],axis=1),columns = [\"name\",\"invasive\"])\n",
    "sub[\"name\"]=sub[\"name\"].astype(int)\n",
    "sub "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we go deeper ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try in another notebook!"
   ]
  }
 ],
 "metadata": {
  "creator": "admin",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
